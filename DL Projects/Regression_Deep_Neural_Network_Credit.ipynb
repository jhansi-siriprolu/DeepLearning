{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict customers future Credit spend based on historical spend data and demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger the model with more nodes in hidden layers, and high numer of epochs the model performance improves\n",
    "### Also tweaking the learning rate and using different activation functions would improve models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Bank of Trust Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32820 entries, 0 to 32819\n",
      "Data columns (total 44 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     32820 non-null  int64  \n",
      " 1   account_type           32820 non-null  object \n",
      " 2   gender                 32820 non-null  object \n",
      " 3   age                    32820 non-null  int64  \n",
      " 4   region_code            32820 non-null  int64  \n",
      " 5   cc_cons_apr            32820 non-null  float64\n",
      " 6   dc_cons_apr            13768 non-null  float64\n",
      " 7   cc_cons_may            32820 non-null  float64\n",
      " 8   dc_cons_may            15481 non-null  float64\n",
      " 9   cc_cons_jun            32820 non-null  float64\n",
      " 10  dc_cons_jun            11523 non-null  float64\n",
      " 11  cc_count_apr           30421 non-null  float64\n",
      " 12  cc_count_may           31667 non-null  float64\n",
      " 13  cc_count_jun           31230 non-null  float64\n",
      " 14  dc_count_apr           13768 non-null  float64\n",
      " 15  dc_count_may           15481 non-null  float64\n",
      " 16  dc_count_jun           17323 non-null  float64\n",
      " 17  card_lim               32811 non-null  float64\n",
      " 18  personal_loan_active   2742 non-null   float64\n",
      " 19  vehicle_loan_active    846 non-null    float64\n",
      " 20  personal_loan_closed   2883 non-null   float64\n",
      " 21  vehicle_loan_closed    1625 non-null   float64\n",
      " 22  investment_1           1426 non-null   float64\n",
      " 23  investment_2           2338 non-null   float64\n",
      " 24  investment_3           1332 non-null   float64\n",
      " 25  investment_4           406 non-null    float64\n",
      " 26  debit_amount_apr       30930 non-null  float64\n",
      " 27  credit_amount_apr      29518 non-null  float64\n",
      " 28  debit_count_apr        31062 non-null  float64\n",
      " 29  credit_count_apr       31062 non-null  float64\n",
      " 30  max_credit_amount_apr  29518 non-null  float64\n",
      " 31  debit_amount_may       30519 non-null  float64\n",
      " 32  credit_amount_may      29415 non-null  float64\n",
      " 33  credit_count_may       30749 non-null  float64\n",
      " 34  debit_count_may        30749 non-null  float64\n",
      " 35  max_credit_amount_may  29415 non-null  float64\n",
      " 36  debit_amount_jun       30625 non-null  float64\n",
      " 37  credit_amount_jun      31277 non-null  float64\n",
      " 38  credit_count_jun       31292 non-null  float64\n",
      " 39  debit_count_jun        31292 non-null  float64\n",
      " 40  max_credit_amount_jun  31277 non-null  float64\n",
      " 41  loan_enq               609 non-null    object \n",
      " 42  emi_active             32820 non-null  float64\n",
      " 43  cc_cons                32820 non-null  int64  \n",
      "dtypes: float64(37), int64(4), object(3)\n",
      "memory usage: 11.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are many columns with null values\n",
    "# check for categorical_null_columns\n",
    "cat_cols = [col for col in df.columns if df[col].dtype == \"O\" ]\n",
    "cat_na = [col for col in df.columns if df[col].dtype == \"O\" and df[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_enq']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [col for col in df.columns if col not in cat_cols and col not in [\"cc_cons\"]]\n",
    "num_na = [col for col in df.columns if col not in cat_cols and df[col].isnull().any() and col not in [\"cc_cons\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dc_cons_apr',\n",
       " 'dc_cons_may',\n",
       " 'dc_cons_jun',\n",
       " 'cc_count_apr',\n",
       " 'cc_count_may',\n",
       " 'cc_count_jun',\n",
       " 'dc_count_apr',\n",
       " 'dc_count_may',\n",
       " 'dc_count_jun',\n",
       " 'card_lim',\n",
       " 'personal_loan_active',\n",
       " 'vehicle_loan_active',\n",
       " 'personal_loan_closed',\n",
       " 'vehicle_loan_closed',\n",
       " 'investment_1',\n",
       " 'investment_2',\n",
       " 'investment_3',\n",
       " 'investment_4',\n",
       " 'debit_amount_apr',\n",
       " 'credit_amount_apr',\n",
       " 'debit_count_apr',\n",
       " 'credit_count_apr',\n",
       " 'max_credit_amount_apr',\n",
       " 'debit_amount_may',\n",
       " 'credit_amount_may',\n",
       " 'credit_count_may',\n",
       " 'debit_count_may',\n",
       " 'max_credit_amount_may',\n",
       " 'debit_amount_jun',\n",
       " 'credit_amount_jun',\n",
       " 'credit_count_jun',\n",
       " 'debit_count_jun',\n",
       " 'max_credit_amount_jun']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_na] = df[num_na].fillna(0)\n",
    "df[cat_na] = df[cat_na].fillna('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('cc_cons', axis = 1)\n",
    "y = df['cc_cons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "## Setting Preprocessor Pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", scaler, num_cols),\n",
    "    (\"cat\",ohe,cat_cols)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply data preprocessing\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Numpy to tensors\n",
    "import torch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype= torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values.reshape(-1,1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train_tensor, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_log_error(y_pred, y_true):\n",
    "    \n",
    "    # adding 1 to mitigate log(0) error\n",
    "    y_pred = torch.clamp(y_pred, min= 0) + 1\n",
    "    y_true = torch.clamp(y_true, min= 0) + 1\n",
    "    \n",
    "    # compute logarithms and then compute squared difference\n",
    "    log_pred = torch.log(y_pred)\n",
    "    log_true = torch.log(y_true)\n",
    "    \n",
    "    squared_log_error = (log_pred - log_true) ** 2\n",
    "    \n",
    "    # Compute mean and then sqrt\n",
    "    mean_sqaure_log_error = torch.mean(squared_log_error)\n",
    "    \n",
    "    rms_log_err = torch.sqrt(mean_sqaure_log_error)\n",
    "    \n",
    "    return rms_log_err\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_data = TensorDataset(X_train_tensor,y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## define network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        #initializing layers\n",
    "        self.fc1 = nn.Linear(X_train_tensor.shape[1],128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,32)\n",
    "        self.fc4 = nn.Linear(32,1)\n",
    "    \n",
    "    #define activation functions\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 2.4569, Test Loss: 2.4836\n",
      "Epoch 10: Train Loss: 1.5236, Test Loss: 1.5428\n",
      "Epoch 15: Train Loss: 1.3553, Test Loss: 1.3658\n",
      "Epoch 20: Train Loss: 1.3257, Test Loss: 1.3310\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2757510144 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()    \n\u001b[1;32m---> 23\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m rms_log_error(model(X_train_tensor), y_train_tensor)\n\u001b[0;32m     24\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m rms_log_error(model(X_test_tensor), y_test_tensor)\n\u001b[0;32m     25\u001b[0m train_loss_list\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m, in \u001b[0;36mrms_log_error\u001b[1;34m(y_pred, y_true)\u001b[0m\n\u001b[0;32m      8\u001b[0m log_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(y_pred)\n\u001b[0;32m      9\u001b[0m log_true \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(y_true)\n\u001b[1;32m---> 11\u001b[0m squared_log_error \u001b[38;5;241m=\u001b[39m (log_pred \u001b[38;5;241m-\u001b[39m log_true) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Compute mean and then sqrt\u001b[39;00m\n\u001b[0;32m     14\u001b[0m mean_sqaure_log_error \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(squared_log_error)\n",
      "File \u001b[1;32mc:\\Users\\scientist-ns\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2757510144 bytes."
     ]
    }
   ],
   "source": [
    "## Training with SGD and momentun 0.9\n",
    "\n",
    "model = Net()\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "num_epochs = 30\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.001, momentum=0.9)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "#Executing the training loop\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch,y_batch in train_loader:\n",
    "        #forward pass\n",
    "        pred = model(X_batch)\n",
    "        loss = rms_log_error(pred, y_batch)\n",
    "        \n",
    "        #backward pass\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "    \n",
    "    train_loss = rms_log_error(model(X_train_tensor), y_train_tensor)\n",
    "    test_loss = rms_log_error(model(X_test_tensor), y_test_tensor)\n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "    \n",
    "    if (epoch+1) % 5 == 0: # printing after every 5 epochs\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using Adam optimizer  \n",
    "* Increasing the number of neurons in hidden layers \n",
    "* Changing the batch size from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## define network\n",
    "# Bigger network, Bigger Batch size and ADAM Optimizer\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        #initializing layers\n",
    "        self.fc1 = nn.Linear(X_train_tensor.shape[1],512)\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.fc3 = nn.Linear(128,32)\n",
    "        self.fc4 = nn.Linear(32,1)\n",
    "    \n",
    "    #define activation functions\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 1.3207, Test Loss: 1.3084\n",
      "Epoch 10: Train Loss: 1.3156, Test Loss: 1.3035\n",
      "Epoch 15: Train Loss: 1.3147, Test Loss: 1.3032\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2757510144 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()    \n\u001b[1;32m---> 21\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m rms_log_error(model(X_train_tensor), y_train_tensor)\n\u001b[0;32m     22\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m rms_log_error(model(X_test_tensor), y_test_tensor)\n\u001b[0;32m     23\u001b[0m train_loss_list\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m, in \u001b[0;36mrms_log_error\u001b[1;34m(y_pred, y_true)\u001b[0m\n\u001b[0;32m      8\u001b[0m log_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(y_pred)\n\u001b[0;32m      9\u001b[0m log_true \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(y_true)\n\u001b[1;32m---> 11\u001b[0m squared_log_error \u001b[38;5;241m=\u001b[39m (log_pred \u001b[38;5;241m-\u001b[39m log_true) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Compute mean and then sqrt\u001b[39;00m\n\u001b[0;32m     14\u001b[0m mean_sqaure_log_error \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(squared_log_error)\n",
      "File \u001b[1;32mc:\\Users\\scientist-ns\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2757510144 bytes."
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "num_epochs = 30\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "#Executing the training loop\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch,y_batch in train_loader:\n",
    "        #forward pass\n",
    "        pred = model(X_batch)\n",
    "        loss = rms_log_error(pred, y_batch)\n",
    "        \n",
    "        #backward pass\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "    \n",
    "    train_loss = rms_log_error(model(X_train_tensor), y_train_tensor)\n",
    "    test_loss = rms_log_error(model(X_test_tensor), y_test_tensor)\n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "    \n",
    "    if (epoch+1) % 5 == 0: # printing after every 5 epochs\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
