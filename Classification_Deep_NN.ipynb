{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18359 entries, 0 to 18358\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             18359 non-null  int64  \n",
      " 1   city                    18359 non-null  object \n",
      " 2   city_development_index  18359 non-null  float64\n",
      " 3   gender                  14261 non-null  object \n",
      " 4   relevent_experience     18359 non-null  object \n",
      " 5   enrolled_university     18017 non-null  object \n",
      " 6   education_level         17902 non-null  object \n",
      " 7   major_discipline        15521 non-null  object \n",
      " 8   experience              18300 non-null  object \n",
      " 9   company_size            13580 non-null  object \n",
      " 10  company_type            13320 non-null  object \n",
      " 11  last_new_job            17992 non-null  object \n",
      " 12  training_hours          18359 non-null  int64  \n",
      " 13  target                  18359 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(10)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Zeta_Analytics Dataset.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"city\", \"enrollee_id\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(\"O\").columns\n",
    "num_cols = [col for col in df.columns if col not in cat_cols]\n",
    "cat_na = [col for col in cat_cols if df[col].isnull().any()]\n",
    "num_na = [col for col in num_cols if df[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_na] = df[cat_na].fillna(\"NA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20    3583\n",
      "5     1309\n",
      "4     1250\n",
      "3     1159\n",
      "6     1125\n",
      "2      992\n",
      "9      979\n",
      "10     967\n",
      "7      950\n",
      "8      755\n",
      "15     695\n",
      "11     667\n",
      "14     602\n",
      "16     549\n",
      "12     497\n",
      "1      452\n",
      "<1     416\n",
      "13     412\n",
      "17     347\n",
      "19     308\n",
      "18     286\n",
      "NA      59\n",
      "Name: experience, dtype: int64\n",
      "1     7567\n",
      "4     4377\n",
      "2     2835\n",
      "0     2186\n",
      "3     1027\n",
      "NA     367\n",
      "Name: last_new_job, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "map_company_size = {\"50-99\" : 3,\n",
    "                    \"100-500\" : 4,\n",
    "                    \"10000+\": 8,\n",
    "                    \"10/49  \" : 2,\n",
    "                    \"1000-4999\" : 6,\n",
    "                    \"<10\" : 1  , \n",
    "                    \"500-999\"  : 5,\n",
    "                    \"5000-9999\" : 7,\n",
    "                    \"NA\": 0}\n",
    "df[\"company_size\"] = df[\"company_size\"].map(map_company_size)\n",
    "\n",
    "tx = [\"experience\",\"last_new_job\"]\n",
    "for col in tx:\n",
    "    df[col] = df[col].astype(\"str\").str.replace(\">\",\"\").replace(\"<\",\"\").replace(\"never\",0).replace(\"<1\",0)\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     7567\n",
       "4     4377\n",
       "2     2835\n",
       "0     2186\n",
       "3     1027\n",
       "NA     367\n",
       "Name: last_new_job, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"last_new_job\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"education_level\"].value_counts()\n",
    "map_edu_levels = {\"Primary School\": 1,\n",
    "                  \"High School\": 2,\n",
    "                  \"Graduate\": 3,\n",
    "                  \"Masters\": 4,\n",
    "                  \"Phd\": 5,\n",
    "                  \"NA\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"target\", axis = 1)\n",
    "y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "could not convert string to float: '<1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\scientist-ns\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:760\u001b[0m, in \u001b[0;36mnanmedian\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 760\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;66;03m# e.g. \"could not convert string to float: 'a'\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '<1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m exp_median \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperience\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[0;32m      2\u001b[0m last_new_job_median \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_new_job\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m## inputing numeric null values after train test split to avoid data leakage\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\scientist-ns\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11917\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.median\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11899\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11900\u001b[0m     _num_doc,\n\u001b[0;32m  11901\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the median of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11915\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11916\u001b[0m ):\n\u001b[1;32m> 11917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmedian(\u001b[38;5;28mself\u001b[39m, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\scientist-ns\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11413\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(\n\u001b[0;32m  11406\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11407\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11411\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11412\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11414\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmedian, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11415\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\scientist-ns\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m  11349\u001b[0m     )\n\u001b[0;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[0;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11352\u001b[0m     )\n\u001b[1;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11354\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11355\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\scientist-ns\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4814\u001b[0m     )\n\u001b[0;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\scientist-ns\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\scientist-ns\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:763\u001b[0m, in \u001b[0;36mnanmedian\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    760\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;66;03m# e.g. \"could not convert string to float: 'a'\"\u001b[39;00m\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m     values[mask] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "\u001b[1;31mTypeError\u001b[0m: could not convert string to float: '<1'"
     ]
    }
   ],
   "source": [
    "exp_median = df[\"experience\"].median()\n",
    "last_new_job_median = df[\"last_new_job\"].median()\n",
    "## inputing numeric null values after train test split to avoid data leakage\n",
    "X_train[\"experience\"]  = X_train[\"experience\"].fillna(exp_median)\n",
    "X_train[\"last_new_job\"] = X_train[\"last_new_job\"].fillna(last_new_job_median)\n",
    "\n",
    "#test data\n",
    "X_test[\"experience\"]  = X_test[\"experience\"].fillna(exp_median)\n",
    "X_test[\"last_new_job\"] = X_test[\"last_new_job\"].fillna(last_new_job_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15934\n",
       "1     2425\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classes for our dataset and neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "def evaluate_and_train_nn_model(model, optimzer, batch_size = 128 , epochs = 25, print_every = 5)\n",
    "    model.train() #setting model to train\n",
    "\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    train_auc_list = []\n",
    "    test_auc_list = [] #AUC score is used as evaluation metric as target data is imbalanced\n",
    "    \n",
    "    ##Convert tensor data into torch based objects\n",
    "    train_dataset = JobChange "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
